# This is as appendix for SIGMOD auther feedback.

## R#2 O2
The table shows the estimation q-error of MSCN and LPCE-I on Join-six queries.
![q_e](https://user-images.githubusercontent.com/52020936/171160080-6c6e4d73-ceda-4b74-8b59-fe75f8663d91.png)

Our main proposal, progressive cardinality estimation, works better for complex queries with many joins. 
To further explain the intuition, we conducted the experiments with queries having varying number of joins on IMDB. Let t_{learn} denote the end-to-end execution when the plan is generated by feeding cardinality values provided by a learned model – LPCE-I.  Let t_{opt} denote the end-to-end execution when the plan is generated by feeding actual cardinality values, which is the optimal execution that we could reach.  Each test set have 100 queries with 2, 4, 6 and 8 joins. We observed that with the increase of join numbers, the average ratio t_{learn}/t_{opt} becomes larger, from 2.2%, 9.3%, 21.7%, to 29.1%. This suggests that there is larger performance gap to optimal execution for complex queries, and it’s more likely that a learned model as such LPCE can contribute to a better plan. 
```
Experiment setting
Let t_{learn} denote end-to-end execution when the plan is generated by feeding cardinalities from a learned model (e.g., LPCE-I).
Let t_{opt} denote end-to-end execution when the plan is generated by feeding actual cardinalities.  
Each query set has 100 queries with 2, 4, 6, 8 joins.
```
![learn_vs_real](https://user-images.githubusercontent.com/52020936/170882637-b9e3f3e3-b1e9-498c-8bef-721fdb304ba4.png)

